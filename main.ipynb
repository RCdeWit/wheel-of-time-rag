{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 14:34:52,961\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.62.176:6379...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m---> 18\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpy_modules\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mebooklib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbs4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/_private/worker.py:1623\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, logging_config, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RayContext(\u001b[38;5;28mdict\u001b[39m(_global_node\u001b[38;5;241m.\u001b[39maddress_info, node_id\u001b[38;5;241m=\u001b[39mnode_id\u001b[38;5;241m.\u001b[39mhex()))\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1624\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaybe you called ray.init twice by accident? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1625\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error can be suppressed by passing in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1626\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_reinit_error=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1627\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.shutdown()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m prior to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.init()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1628\u001b[0m         )\n\u001b[1;32m   1630\u001b[0m _system_config \u001b[38;5;241m=\u001b[39m _system_config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_system_config, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import psutil\n",
    "import ray\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from ebooklib import epub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LLM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this interactively in your terminal to generate a config\n",
    "rayllm gen-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the serve app to production with a given service name.\n",
    "# Reference the serve file created in step 1\n",
    "!anyscale service deploy -f serve_mistral_7b.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_llm(service_url: str, prompt: str, model: str =\"mistralai/Mistral-7B-Instruct-v0.1\", temperature: float = 0, **kwargs):\n",
    "\n",
    "    # Ensure URL has a trailing backslash\n",
    "    if not service_url.endswith(\"/\"):\n",
    "        service_url += \"/\"\n",
    "    \n",
    "    if \"/routes\" in service_url:\n",
    "        raise ValueError(\"service_url must end with '.com'\")\n",
    "\n",
    "    # Initialize a client to perform API requests\n",
    "    client = openai.OpenAI(\n",
    "        base_url=ANYSCALE_SERVICE_BASE_URL + \"v1\",\n",
    "        api_key=ANYSCALE_API_KEY,\n",
    "    )\n",
    "    \n",
    "    # Call the chat completions endpoint\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            # Prime the system with a system message - a common best practice\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            # Send the user message with the proper \"user\" role and \"content\"\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = \"https://wheel-of-time-rag-3136s.cld-8lqvbtr41isy21zu.s.anyscaleuserdata.com/\"\n",
    "prompt = \"Tell me something about Wheel of Time\"\n",
    "response = prompt_llm(\"service_url\", prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download epubs from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded library/00 - New Spring.epub to data/library/00 - New Spring.epub\n",
      "Downloaded library/01 - The Eye of the World.epub to data/library/01 - The Eye of the World.epub\n",
      "Downloaded library/02 - The Great Hunt.epub to data/library/02 - The Great Hunt.epub\n",
      "Downloaded library/03 - The Dragon Reborn.epub to data/library/03 - The Dragon Reborn.epub\n",
      "Downloaded library/04 - The Shadow Rising.epub to data/library/04 - The Shadow Rising.epub\n",
      "Downloaded library/05 - The Fires of Heaven.epub to data/library/05 - The Fires of Heaven.epub\n",
      "Downloaded library/06 - Lord of Chaos.epub to data/library/06 - Lord of Chaos.epub\n",
      "Downloaded library/07 - A Crown of Swords.epub to data/library/07 - A Crown of Swords.epub\n",
      "Downloaded library/08 - The Path of Daggers.epub to data/library/08 - The Path of Daggers.epub\n",
      "Downloaded library/09 - Winter's Heart.epub to data/library/09 - Winter's Heart.epub\n",
      "Downloaded library/10 - Crossroads of Twilight.epub to data/library/10 - Crossroads of Twilight.epub\n",
      "Downloaded library/11 - Knife of Dreams.epub to data/library/11 - Knife of Dreams.epub\n",
      "Downloaded library/12 - The Gathering Storm.epub to data/library/12 - The Gathering Storm.epub\n",
      "Downloaded library/13 - Towers of Midnight.epub to data/library/13 - Towers of Midnight.epub\n",
      "Downloaded library/14 - A Memory of Light.epub to data/library/14 - A Memory of Light.epub\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "def download_s3_bucket(bucket_name, local_dir='/data'):\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Ensure local directory exists\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "    \n",
    "    # List all objects in the S3 bucket\n",
    "    for obj in s3.list_objects_v2(Bucket=bucket_name)['Contents']:\n",
    "        s3_key = obj['Key']\n",
    "        local_path = os.path.join(local_dir, s3_key)\n",
    "        \n",
    "        # Create local directory structure if needed\n",
    "        if not os.path.exists(os.path.dirname(local_path)):\n",
    "            os.makedirs(os.path.dirname(local_path))\n",
    "        \n",
    "        # Download the file\n",
    "        s3.download_file(bucket_name, s3_key, local_path)\n",
    "        print(f\"Downloaded {s3_key} to {local_path}\")\n",
    "\n",
    "# Usage\n",
    "BUCKET_NAME = 'rag-wheel-of-time'\n",
    "LOCAL_DATA_DIR = Path(\"./data/\")\n",
    "\n",
    "download_s3_bucket(BUCKET_NAME, LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse epubs to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_epub_content(epub_file: Path) -> list:\n",
    "    \"\"\"Extracts and returns text content from an EPUB file.\"\"\"\n",
    "    book = epub.read_epub(epub_file)\n",
    "    content = []\n",
    "\n",
    "    for item in book.get_items():\n",
    "        # Check if the media type is HTML/XHTML\n",
    "        if item.media_type == 'application/xhtml+xml':\n",
    "            soup = BeautifulSoup(item.get_body_content(), 'html.parser')\n",
    "            # Extract text from each HTML section\n",
    "            content.append(soup.get_text())\n",
    "\n",
    "    # Join all sections to return as a single string\n",
    "    return '\\n'.join(content)\n",
    "\n",
    "def parse_epub_directory(directory_path: Path) -> dict:\n",
    "    \"\"\"Parses all EPUB files in a directory and returns a dictionary with file names and content.\"\"\"\n",
    "    epub_texts = {}\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.epub'):\n",
    "            epub_path = os.path.join(directory_path, filename)\n",
    "            text = parse_epub_content(epub_path)\n",
    "            epub_texts[filename] = text\n",
    "            \n",
    "    return epub_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book00 = parse_epub_content('data/library/00 - New Spring.epub')\n",
    "book01 = parse_epub_content('data/library/01 - The Eye of the World.epub')\n",
    "# book02 = parse_epub_content('data/library/02 - The Great Hunt.epub')\n",
    "# book03 = parse_epub_content('data/library/03 - The Dragon Reborn.epub')\n",
    "# book04 = parse_epub_content('data/library/04 - The Shadow Rising.epub')\n",
    "# book05 = parse_epub_content('data/library/05 - The Fires of Heaven.epub')\n",
    "# book06 = parse_epub_content('data/library/06 - Lord of Chaos.epub')\n",
    "# book07 = parse_epub_content('data/library/07 - A Crown of Swords.epub')\n",
    "# book08 = parse_epub_content('data/library/08 - The Path of Daggers.epub')\n",
    "# book09 = parse_epub_content('data/library/09 - Winter\\'s Heart.epub')\n",
    "# book10 = parse_epub_content('data/library/10 - Crossroads of Twilight.epub')\n",
    "# book11 = parse_epub_content('data/library/11 - Knife of Dreams.epub')\n",
    "# book12 = parse_epub_content('data/library/12 - The Gathering Storm.epub')\n",
    "# book13 = parse_epub_content('data/library/13 - Towers of Midnight.epub')\n",
    "# book14 = parse_epub_content('data/library/14 - A Memory of Light.epub')\n",
    "\n",
    "print(book01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/home/ray/anaconda3/lib/python3.9/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "directory_path = LOCAL_DATA_DIR / 'library'\n",
    "epub_data = parse_epub_directory(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split books into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128  #  Chunk size is usually specified in tokens\n",
    "words_to_tokens = 1.2  # Heuristic for converting tokens to words\n",
    "chunk_size_in_words = int(chunk_size // words_to_tokens)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size_in_words,\n",
    "    length_function=lambda x: len(x.split()),\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for title, text in epub_data.items():\n",
    "    for chunk in splitter.split_text(text):\n",
    "        chunks.append(\n",
    "            {\n",
    "                \"text\": chunk,\n",
    "                \"book_title\": title,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Praise for THE WHEEL OF TIME®\\n“Unlike some of the authors of mega-sagas, Jordan chooses his words with care, creating people and events that have earned him an enormous readership. For sheer imagination and storytelling skill . . . The Wheel of Time now rivals Tolkien’s The Lord of the Rings.”\\n—Publishers Weekly (starred review)\\n“Jordan succeeds in carrying forward his stunning world-building in this detailed story of a struggle between good and evil. The story continues with its myriad threads and subplots, carrying the reader inexorably toward an unpredictable conclusion.”\\n—SF Site', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“The battle scenes have the breathless urgency of firsthand experience, and the . . . evil laced into the forces of good, the dangers latent in any promised salvation, the sense of the unavoidable onslaught of unpredictable events bear the marks of American national experience during the last three de cades.”\\n—The New York Times', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“His writing is distinguished . . . by the richness of its fabric, with all the charm and naiveté of the Brothers Grimm and the social/moral commentary of Huxley’s Brave New World. With his well-fleshed-out characters, dark imagery, comic relief, vivid landscapes, and a fascinating sense of timelessness, Jordan has created a complex literature with a language and reality all its own.”\\n—Brewster Milton Robertson, BookPage', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“Throughout Jordan’s preeminent high-fantasy saga . . . the characters (minor as well as major), the world, and the source of powers have remained remarkably rich and consistent—no mean feat. . . . Amid all the Sturm und Drang, however, is a finely tuned comic strain that both leavens the story and adds to its development. A major fantasy epic.”\\n—Booklist\\n“Truth is not only stranger, it’s richer than fiction, but Jordan’s fictional universe approaches the variety and complexity of the real. . . . Plotlines [are] strummed with resonating long-wave rhythms something like Beethoven’s Eroica.”\\n—Robert Knox, MPG Newspapers', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“Adventure and mystery and dark things that move in the night—a combination of Robin Hood and Stephen King that is hard to resist . . . Furthermore, Jordan makes the reader . . . put down the book regretting the wait for the next title in the series.”\\n—Milwaukee Sentinel\\n“The Wheel of Time [is] rapidly becoming the definitive American fantasy saga. It is a fantasy tale seldom equaled and still less often surpassed in English.”\\n—Chicago Sun-Times\\n“Can’t recommend starting anywhere but at the beginning, but the volumes only get richer as they go along.”\\n—Locus', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“In the decades since J. R. R. Tolkien’s Lord of the Rings trilogy was published, many fantasy writers have tried to capture the spirit of that seminal work. While many have been able to imitate the style, develop a similarly swift and complex plot, and create convincing characters, none had captured the spirit of small men and mighty, struggling against a force of overwhelming evil. Robert Jordan has.”\\n—Ottawa Citizen\\n“Magic and pacing and detail and human involvement, with a certain subtlety of presentation and a grand central vision. Robert Jordan . . . is a lot of writer!”\\n—Piers Anthony', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“Jordan has a powerful vision of good and evil—but what strikes me as most pleasurable . . . is all the fascinating people moving through a rich and interesting world.”\\n—Orson Scott Card\\n“Jordan’s characters [are] fleshed out with the strengths and weaknesses of real men and women. . . . Invokes the end-of-the-world milieu of Stephen King’s The Stand.”\\n—The Post and Courier (Charleston, South Carolina)\\n“Jordan writes with the stark vision of light and darkness, and sometimes childlike sense of wonder, that permeates J. R. R. Tolkien’s works. His style is undebatably his own.”\\n—The Pittsburgh Press', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“Jordan’s multivolume epic continues to live up to its high ambitions. Complex plotting, an array of strong characters, lavish detail, and a panoramic scope make this series a feast for fantasy aficionados. . . . Richly detailed and vividly imagined.”\\n—Library Journal\\n“Jordan’s writing is clear and his vision is fascinating, as are the philosophies that run his characters. And speaking of characters, a more interesting bunch I would be hard put to name.”\\n—Science Fiction Review', 'book_title': '08 - The Path of Daggers.epub'}, {'text': '“The complex philosophy behind The Wheel of Time series is expounded so simply the reader often gives a start of surprise at returning to the real world. Rand’s adventures are not finished and neither is this thinking-person’s fantasy series.”\\n—Brunswick Sentinel (Australia)\\n“Robert Jordan can write one hell of a story. . . . [He] keeps the suspense acute and the surprises and invention beautifully paced. Compelling. An exhilarating experience.”\\n—Isaac Asimov’s Science Fiction Magazine', 'book_title': '08 - The Path of Daggers.epub'}, {'text': 'THE WHEEL OF TIME®\\nby Robert Jordan\\nThe Eye of the WorldThe Great HuntThe Dragon RebornThe Shadow RisingThe Fires of HeavenLord of ChaosA Crown of SwordsThe Path of DaggersWinter’s HeartCrossroads of TwilightKnife of Dreams\\nby Robert Jordanand Brandon Sanderson\\nThe Gathering Storm\\n\\n\\nTHE PATHOFDAGGERS\\nROBERT JORDAN', 'book_title': '08 - The Path of Daggers.epub'}]\n"
     ]
    }
   ],
   "source": [
    "# Print sample\n",
    "print(chunks[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embeddings from chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('thenlper/gte-large', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 14:24:08,852\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-10-30_13-15-29_786163_2344/logs/ray-data\n",
      "2024-10-30 14:24:08,852\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddc3fc9187840b78bd3ab2e56c1beff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fc3d9a094841d3bbf96acd2bd385b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717bc80bc6df460ea6cf999c1bca743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# library_path = \".\" / LOCAL_DATA_DIR / \"library\"\n",
    "# file_paths = [str(f\"/{file}\") for file in library_path.rglob('*') if file.is_file()]\n",
    "\n",
    "# print(file_paths)\n",
    "\n",
    "books = ray.data.read_binary_files(\n",
    "    paths = \"s3://rag-wheel-of-time/\",\n",
    "    )\n",
    "books.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 14:37:18,593\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-10-30_13-15-29_786163_2344/logs/ray-data\n",
      "2024-10-30 14:37:18,593\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[FlatMap(parse_epub_content)] -> LimitOperator[limit=2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99de43635f514bac9c8a3ff75050a16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666def439c2142c19e6023e6a44d7626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060a7f5153794e849654f1f867a4b55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c95566bc4e4c67828e0ba882ae74bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- FlatMap(parse_epub_content) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23b2149dd1e4de4863f7d92433e9143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=2 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 14:37:18,690\tERROR streaming_executor_state.py:469 -- An exception was raised from a task of operator \"ExpandPaths\". Dataset execution will now abort. To ignore this exception and continue, set DataContext.max_errored_blocks.\n",
      "2024-10-30 14:37:18,699\tERROR exceptions.py:73 -- Exception occurred in Ray Data or Ray Core internal code. If you continue to see this error, please open an issue on the Ray project GitHub page with the full stack trace below: https://github.com/ray-project/ray/issues/new/choose\n",
      "2024-10-30 14:37:18,700\tERROR exceptions.py:81 -- Full stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/exceptions.py\", line 49, in handle_trace\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/plan.py\", line 433, in execute_to_iterator\n",
      "    bundle_iter = itertools.chain([next(gen)], gen)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/interfaces/executor.py\", line 37, in __next__\n",
      "    return self.get_next()\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/legacy_compat.py\", line 76, in get_next\n",
      "    bundle = self._base_iterator.get_next(output_split_idx)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor.py\", line 153, in get_next\n",
      "    item = self._outer._output_node.get_output_blocking(\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor_state.py\", line 296, in get_output_blocking\n",
      "    raise self._exception\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor.py\", line 232, in run\n",
      "    continue_sched = self._scheduling_loop_step(self._topology)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor.py\", line 287, in _scheduling_loop_step\n",
      "    num_errored_blocks = process_completed_tasks(\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor_state.py\", line 470, in process_completed_tasks\n",
      "    raise e from None\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor_state.py\", line 437, in process_completed_tasks\n",
      "    bytes_read = task.on_data_ready(\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/interfaces/physical_operator.py\", line 105, in on_data_ready\n",
      "    raise ex from None\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/interfaces/physical_operator.py\", line 101, in on_data_ready\n",
      "    ray.get(block_ref)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/_private/worker.py\", line 2664, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RaySystemError): \u001b[36mray::ExpandPaths()\u001b[39m (pid=7795, ip=10.0.13.245)\n",
      "  At least one of the input arguments for this task could not be computed:\n",
      "ray.exceptions.RaySystemError: System error: No module named 'ebooklib'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/cloudpickle/cloudpickle.py\", line 457, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'ebooklib'\n"
     ]
    },
    {
     "ename": "RayTaskError(RaySystemError)",
     "evalue": "\u001b[36mray::ExpandPaths()\u001b[39m (pid=7795, ip=10.0.13.245)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RaySystemError: System error: No module named 'ebooklib'\ntraceback: Traceback (most recent call last):\n  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/cloudpickle/cloudpickle.py\", line 457, in subimport\n    __import__(name)\nModuleNotFoundError: No module named 'ebooklib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mSystemException\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRayTaskError(RaySystemError)\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(content)\n\u001b[1;32m     16\u001b[0m books_parsed \u001b[38;5;241m=\u001b[39m books\u001b[38;5;241m.\u001b[39mflat_map(parse_epub_content)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mbooks_parsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/dataset.py:2423\u001b[0m, in \u001b[0;36mDataset.take\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m   2420\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2422\u001b[0m limited_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit(limit)\n\u001b[0;32m-> 2423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m limited_ds\u001b[38;5;241m.\u001b[39miter_rows():\n\u001b[1;32m   2424\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m limit:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/iterator.py:238\u001b[0m, in \u001b[0;36mDataIterator.iter_rows.<locals>._wrapped_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_iterator\u001b[39m():\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_iterable:\n\u001b[1;32m    239\u001b[0m         batch \u001b[38;5;241m=\u001b[39m BlockAccessor\u001b[38;5;241m.\u001b[39mfor_block(BlockAccessor\u001b[38;5;241m.\u001b[39mbatch_to_block(batch))\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39miter_rows(public_row_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/iterator.py:155\u001b[0m, in \u001b[0;36mDataIterator.iter_batches.<locals>._create_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Iterate through the dataset from the start each time\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# _iterator_gen is called.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# This allows multiple iterations of the dataset without\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# needing to explicitly call `iter_batches()` multiple times.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m (\n\u001b[1;32m    152\u001b[0m     ref_bundles_iterator,\n\u001b[1;32m    153\u001b[0m     stats,\n\u001b[1;32m    154\u001b[0m     blocks_owned_by_consumer,\n\u001b[0;32m--> 155\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_ref_bundle_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m    158\u001b[0m     iter_batches(\n\u001b[1;32m    159\u001b[0m         ref_bundles_iterator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    173\u001b[0m dataset_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_tag()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/iterator/iterator_impl.py:28\u001b[0m, in \u001b[0;36mDataIteratorImpl._to_ref_bundle_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_ref_bundle_iterator\u001b[39m(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Iterator[RefBundle], Optional[DatasetStats], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m     27\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_dataset\n\u001b[0;32m---> 28\u001b[0m     ref_bundles_iterator, stats, executor \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_to_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     ds\u001b[38;5;241m.\u001b[39m_current_executor \u001b[38;5;241m=\u001b[39m executor\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ref_bundles_iterator, stats, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/exceptions.py:89\u001b[0m, in \u001b[0;36momit_traceback_stdout.<locals>.handle_trace\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSystemException\u001b[39;00m()\n",
      "\u001b[0;31mRayTaskError(RaySystemError)\u001b[0m: \u001b[36mray::ExpandPaths()\u001b[39m (pid=7795, ip=10.0.13.245)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RaySystemError: System error: No module named 'ebooklib'\ntraceback: Traceback (most recent call last):\n  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/cloudpickle/cloudpickle.py\", line 457, in subimport\n    __import__(name)\nModuleNotFoundError: No module named 'ebooklib'"
     ]
    }
   ],
   "source": [
    "def parse_epub_content(epub_file) -> str:\n",
    "    \"\"\"Extracts and returns text content from an EPUB file.\"\"\"\n",
    "    book = epub.read_epub(epub_file)\n",
    "    content = []\n",
    "\n",
    "    for item in book.get_items():\n",
    "        # Check if the media type is HTML/XHTML\n",
    "        if item.media_type == 'application/xhtml+xml':\n",
    "            soup = BeautifulSoup(item.get_body_content(), 'html.parser')\n",
    "            # Extract text from each HTML section\n",
    "            content.append(soup.get_text())\n",
    "\n",
    "    # Join all sections to return as a single string\n",
    "    return '\\n'.join(content)\n",
    "\n",
    "books_parsed = books.flat_map(parse_epub_content)\n",
    "books_parsed.take(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
